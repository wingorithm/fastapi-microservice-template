<h1 align=center><strong>Fastapi Microservice Template</strong></h1>

A template to jumpstart your microservice projects using FastAPI. This repository provides a structured foundation inspired by real-world applications, so you can focus on building features instead of boilerplate.
> ‚ö†Ô∏è This template is not a drop-in production deployment, but it‚Äôs built on production-grade principles (modular architecture, service discovery, API gateway, centralized config). It gives you a strong foundation to scale toward production.

<img width="1922" height="1004" alt="fastapi-microservice" src="https://github.com/user-attachments/assets/fd62300a-cd62-4b5c-bc9c-7f56c0a5cc74" />

## What's The Tech-Stack?
* üê≥ [Dockerized](https://www.docker.com/)
* üêò [Asynchronous PostgreSQL](https://www.postgresql.org/docs/current/libpq-async.html)
* üêç [FastAPI Backend Boilerplate](https://fastapi.tiangolo.com/)
* üíæ [Alembic Auto Migration](https://github.com/sqlalchemy/alembic)
* ‚òéÔ∏è [Consul Service Registry](https://www.hashicorp.com/en/products/consul)
* üìë [Consul KV](https://www.hashicorp.com/en/products/consul)
* üëÆ [Kong Gateway](https://konghq.com/products/kong-gateway)
* ü™™ [Registrator](https://hub.docker.com/r/hypolas/registrator)
* üóÇÔ∏è [UV package manager](https://docs.astral.sh/uv/)

## What's The Boilerplate Structure?
```shell
.github/
‚îú‚îÄ‚îÄ workflows/
    ‚îú‚îÄ‚îÄ docker-publish.yml              # A CI file for the backend app that connected to github container registry
service-a/
‚îú‚îÄ‚îÄ app/
    ‚îú‚îÄ‚îÄ api/
        ‚îú‚îÄ‚îÄ dependencies/               # Dependency injections folder
        ‚îú‚îÄ‚îÄ routes/                     # Endpoints
            ‚îú‚îÄ‚îÄ service_routes.py       # Service's routes / controller
        ‚îú‚îÄ‚îÄ endpoints.py                # Endpoint registration
    ‚îú‚îÄ‚îÄ config/
        ‚îú‚îÄ‚îÄ settings/
            ‚îú‚îÄ‚îÄ base.py                 # Base settings / settings parent class
                ‚îú‚îÄ‚îÄ development.py      # dev env settings
                ‚îú‚îÄ‚îÄ environments.py     # Enum with PROD, DEV, STAGE environment
                ‚îú‚îÄ‚îÄ production.py       # prod env settings
                ‚îú‚îÄ‚îÄ staging.py          # uat env settings
        ‚îú‚îÄ‚îÄ events.py                   # Registration of global events
        ‚îú‚îÄ‚îÄ manager.py                  # Manage config properties fetch to consul kv or local .env
    ‚îú‚îÄ‚îÄ model/
        ‚îú‚îÄ‚îÄ db/
            ‚îú‚îÄ‚îÄ account.py               # Pokemon class for database entity
        ‚îú‚îÄ‚îÄ schemas/
            ‚îú‚îÄ‚îÄ global_response.py       # Standardized global api response wrapper to promote consitency
            ‚îú‚îÄ‚îÄ pokemon_dto.py           # Pokemon Data Transfer Object classes for data encapsulation and validation
            ‚îú‚îÄ‚îÄ base.py                  # Base class with pydantic for data validation objects
    ‚îú‚îÄ‚îÄ repository/
        ‚îú‚îÄ‚îÄ crud/
            ‚îú‚îÄ‚îÄ pokemon_repository.py   # Repository class for C. R. U. D. operations for Pokemon entity
            ‚îú‚îÄ‚îÄ base.py                 # Base class for C. R. U. D. operations
        ‚îú‚îÄ‚îÄ migrations/
            ‚îú‚îÄ‚îÄ versions/               # Generated migration scripts for tracking database schema changes history,
            ‚îú‚îÄ‚îÄ env.py                  # Generated via alembic for automigration (adjusted for specific schema)
            ‚îú‚îÄ‚îÄ script.py.mako          # Generated via alembic
        ‚îú‚îÄ‚îÄ proxy/
            ‚îú‚îÄ‚îÄ service_b_proxy.py      # Proxy class (client) to call other remote services via consul service discovery
            ‚îú‚îÄ‚îÄ base.py                 # Base class for proxy / client communication
        ‚îú‚îÄ‚îÄ base.py                     # Entry point for alembic automigration
        ‚îú‚îÄ‚îÄ database.py                 # Database class with engine and session
        ‚îú‚îÄ‚îÄ events.py                   # Registration of database events
        ‚îú‚îÄ‚îÄ table.py                    # Custom SQLAlchemy Base class
    ‚îú‚îÄ‚îÄ api/
        ‚îú‚îÄ‚îÄ crud_service.py             # Service layer for storing all business logic
    ‚îú‚îÄ‚îÄ utilities/                      # Folders to store your util class and logic
        ‚îú‚îÄ‚îÄ datetime_formatter.py
‚îú‚îÄ‚îÄ .env-example                        # Our bootstrap properties in local development (rename this to '.env') 
‚îú‚îÄ‚îÄ .env-local                          # Our application properties based on environtment (fell free to add .env-staging, prod, etc) 
‚îú‚îÄ‚îÄ Dockerfile                          # Docker configuration file for backend service
‚îú‚îÄ‚îÄ README.md                           # Documentation for backend app
‚îú‚îÄ‚îÄ alembic.ini                         # Automatic database migration configuration (adjusted for specific schema)
‚îú‚îÄ‚îÄ main.py                             # Our main backend server app
‚îú‚îÄ‚îÄ pyproject.toml                      # Our source of truth for project metadata, dependencies, and build system
‚îú‚îÄ‚îÄ requirements.txt                    # Packages installed and list of dependency for backend app
‚îú‚îÄ‚îÄ uv.lock                             # lockfile generated by uv
```

## What's The Scenario?
we'll have two primary interaction flows, orchestrated through an API Gateway.

### 1st Scenario : Find a Trainer for a Pok√©mon
``` shell
Client -> GET {gateway_url}/pokemons/get-data -> Service-A -> Service-B -> Client
```
Workflow:
1. A client sends a GET request to `/pokemons/get-data` endpoint on the API Gateway.
2. The gateway routes the request to `service-a` (the Pok√©mon Service).
3. `service-a` fetches data for a random Pok√©mon.
4. `service-a` then calls `service-b` (the Trainer Service) to find a trainer who would be a good match for the selected Pok√©mon.
5. The combined Pok√©mon and Trainer data is aggregated and returned to the client. The response will look like below example

<p align="center">
  <img src="https://github.com/user-attachments/assets/7840747a-933e-4ea2-bfa3-3645bd7633dd" alt="1st journey pokemon to trainer" width="400"/>
</p>

### 2nd Scenario: Find a Pok√©mon for a Trainer
``` shell
Client -> GET {gateway_url}/trainers/get-data -> Service-B -> Service-A -> Client
```
Workflow:
1. A client sends a GET request to `/trainers/get-data` endpoint on the API Gateway.
2. The gateway routes the request to `service-b` (the Trainer Service).
3. `service-b` fetches data for a random trainer.
4. `service-b` then calls `service-a` (the Pok√©mon Service) to find a Pok√©mon that fits the trainer's profile or specialty.
5. The combined Trainer and Pok√©mon data is aggregated and returned to the client. The response will look like below example

<p align="center">
  <img src="https://github.com/user-attachments/assets/9ea6c7bf-ed16-4cd3-becd-87084908f007" alt="2nd journey trainer to pokemon" width="400"/>
</p>


## How to Setup?
This project is now structured using multiple docker-compose files to separate the core infrastructure from the application services. This is the practice for managing different service lifecycles and environments.
```shell
‚îú‚îÄ‚îÄ docker-compose.yml           # Application services (service_a, service_b, etc.)
‚îú‚îÄ‚îÄ docker-compose.infra.yml     # Infrastructure (PostgreSQL, Consul, Registrator, Kong)
‚îî‚îÄ‚îÄ postgres-init/
    ‚îî‚îÄ‚îÄ init-multi-db.sh         # bootstrap file for Postgres
```

### 1. Start the Infrastructure Stack
First, launch the infrastructure services like the database, service discovery, and API gateway.
```shell
docker-compose -f docker-compose.infra.yml up -d
```
After that check all containers, ensure their healthiness.
> ‚ÑπÔ∏è Note: The `kong-bootstrap` container is expected to run once to set up the database and then exit. Seeing it with a status of `Exited (0)` is normal.

### 2. Verify Database Initialization
The `postgres-init` script automatically creates the necessary databases and schemas. Connect to your PostgreSQL instance and verify that the following structure exists:
```plaintext
‚îú‚îÄ‚îÄ kong
    ‚îî‚îÄ‚îÄ public
        ‚îî‚îÄ‚îÄ 35 Kong's internal tables)
‚îú‚îÄ‚îÄ microservice
    ‚îî‚îÄ‚îÄservice_a
    ‚îî‚îÄ‚îÄservice_b
```

### 3. Setup & Inspect Consul Service Registry
Consul provides a UI to inspect the service mesh and manage configuration.
> using UI is not weak, it not just easier, but help us reduce human error üòé

1. Verify Service Registration:
Open the Consul UI at `http://localhost:8500` Navigate to the Services tab. You should see `service-a` and `service-b` listed as healthy.
<p align="center">
<img src="https://github.com/user-attachments/assets/fbb27c7c-1ce9-4531-b7a6-3047721341b2" alt="Consul Services UI" width="700"/>
</p>

2. Set Up Centralized Configuration:
Use the Key/Value tab to store centralized configuration that your serv will use, get the config in `.env-local`.
<p align="center">
<img src="https://github.com/user-attachments/assets/1108ce91-7836-49e1-8a03-860b8f75cae0" alt="Consul Key/Value UI" width="700"/>
</p>

### 4. Start the Application Services
With the infrastructure running, start the service-a and service-b applications.
```shell
docker-compose -f docker-compose.yml up -d
```

On startup, each service automatically runs its database migrations using `Alembic`, creating the tables defined in the codebase.

> ‚ö†Ô∏è Important: To populate the database with sample data required for the endpoints to work, manually execute the SQL commands in `postgres-init/example-data.sql`

> ‚ÑπÔ∏è DO NOT change version data in `*/app/repository/migration/versions/*.py`, if you need to change the migration follow instruction at section 'How To Modify The Code?'

### 5. Finale; Setup Your Gateway (Kong)
Finally, expose the services to the outside world by configuring routes in Kong. You can use the Kong Admin UI, available at `http://localhost:8001`.
1. Create an upstream service for `service-a`:
   A Kong Service points to a specific backend. Configure it to use Consul for service discovery.
    - Name: `pokemon-service`
    - Protocol: `http`
    - Host: `service-a.service.consul` (This special address lets Kong find `service-a` via Consul)
    - Port: `80`
2. Create an upstream service for `service-b`:
   Do the same for the trainer service.
    - Name: `trainer-service`
    - Protocol: `http`
    - Host: `service-b.service.consul`
    - Port: `80`
    <p align="center"><img src="https://github.com/user-attachments/assets/32c5cd0c-b118-4404-a9e0-4a120a48389d" alt="Kong Services List" width="900"/></p>
3. Create a route for `pokemon-service`:
   A Route defines how requests are sent to a Service. Create a route that forwards requests with the `/pokemons` path to the `pokemon-service`.
    - Name: `pokemon-service-route`
    - Service: Select `pokemon-service`
    - Path: `/pokemons`
4. Create a route for `trainer-service`:
   Similarly, create a route that forwards requests with the `/trainers` path to the `trainer-service`.
    - Name: `trainer-service-route`
    - Service: Select `trainer-service`
    - Path: `/trainers`
    <p align="center"><img src="https://github.com/user-attachments/assets/e8758bf3-5218-4713-9e15-93c9d8ae0612" alt="Kong Routes List" width="900"/></p>
    
Your setup is now complete! Happy coding üêû You can begin making requests to the API Gateway (e.g., `http://localhost:8000/pokemons/get-data`).

## How To Modify The Service?
This guide outlines the development workflow for modifying a backend service, such as adding a new feature that requires dependency changes or database schema updates.

### Prerequisites
Before you begin, ensure you are working inside the specific service's directory (e.g., service-a/) and have activated the virtual environment.
```shell
cd service-a/
source .venv/bin/activate
uv sync
```

1. Managing Dependencies, 
When you need to add, update, or remove a Python package, follow this process.
    - Install a New Package:
    Use `uv` to add a new package. It will automatically update the `pyproject.toml` and `uv.lock` files.
    ```shell
    uv add "package-name"
    ```
    - Update requirements.txt:
     To ensure the requirements.txt file stays in sync for compatibility with other tools, regenerate it from the lock file.
    ```shell
    uv pip freeze > requirements.txt
    ```
2. Changing the Database Schema, 
This project uses Alembic to manage database migrations. The process is semi-automated.
    - Modify Your SQLAlchemy Models:
      First, make the desired changes directly in your Python code. For example, add a new column to a model in `app/models.py` or    create an entirely new model file.
    - Generate a Migration Script:
      Once your models are updated, run Alembic's autogenerate command. This will compare your SQLAlchemy models against the current state of the database and create a new migration script.
      ```Shell
      example
      alembic revision --autogenerate -m "Add description column to Pokemon model"
      ```
    This creates a new file inside `app/repository/migration/versions/.` You should review this file to ensure it accurately reflects your intended changes.
    > ‚ÑπÔ∏è This template is configured to handle database upgrades automatically by simply run the application.
 
3. Running the Service
    ```
    python main.py
    ```
    Firstly the service will detect and apply any pending Alembic migrations on startup before the application begins serving requests, then your database schema is now up-to-date with your models, and the service is running with your latest code changes.
